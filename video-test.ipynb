{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24680,"status":"ok","timestamp":1686597857028,"user":{"displayName":"KHIÊM TRẦN TRỌNG","userId":"16845824126454704990"},"user_tz":-420},"id":"qKbGMzGGZM5S","outputId":"e8f9bc26-ff9f-4b7a-881b-ee588e950e36"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":571,"status":"ok","timestamp":1686597857597,"user":{"displayName":"KHIÊM TRẦN TRỌNG","userId":"16845824126454704990"},"user_tz":-420},"id":"dnXXjQFwZerU","outputId":"23adc129-0f47-4ac3-d0ad-1bee4072df2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/UIT/nghien-cuu-khoa-hoc/Projects/do-an-1\n"]}],"source":["cd \"/content/drive/MyDrive/UIT/nghien-cuu-khoa-hoc/Projects/do-an-1\""]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3926,"status":"ok","timestamp":1686597861522,"user":{"displayName":"KHIÊM TRẦN TRỌNG","userId":"16845824126454704990"},"user_tz":-420},"id":"BXMDQvX2ZgF6"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from keras.preprocessing import image\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from keras.utils import img_to_array, load_img\n","from keras import models\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHbnrJSwaPR_"},"outputs":[],"source":["retrievedModel = models.load_model(\"model.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LL-kD2yTfr3S"},"outputs":[],"source":["face_haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"/content/drive/MyDrive/UIT/nghien-cuu-khoa-hoc/Projects/do-an-1/emotion-recognition/haarcascade_frontalface_default.xml\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m1Hx8OzXf7_a"},"outputs":[],"source":["cap = cv2.VideoCapture(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"elapsed":3,"status":"error","timestamp":1684078053489,"user":{"displayName":"KHIÊM TRẦN TRỌNG","userId":"16845824126454704990"},"user_tz":-420},"id":"pBxCI1nAwy6w","outputId":"34b59f10-3ba3-4bc9-af5c-8c44ec8fb6f9"},"outputs":[{"ename":"IndentationError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    if not ret:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"]}],"source":["while True:\n","     ret, test_img = cap.read()  # captures frame and returns boolean value and captured image\n","    # if not ret:\n","    #     continue\n","    gray_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n","\n","    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n","\n","    for (x, y, w, h) in faces_detected:\n","        cv2.rectangle(test_img, (x, y), (x + w, y + h), (255, 0, 0), thickness=7)\n","        roi_gray = gray_img[y:y + w, x:x + h]  # cropping region of interest i.e. face area from  image\n","        roi_gray = cv2.resize(roi_gray, (224, 224))\n","        img_pixels = image.img_to_array(roi_gray)\n","        img_pixels = np.expand_dims(img_pixels, axis=0)\n","        img_pixels /= 255\n","\n","        predictions = retrievedModel.predict(img_pixels)\n","\n","        # find max indexed array\n","        max_index = np.argmax(predictions[0])\n","\n","        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n","        predicted_emotion = emotions[max_index]\n","\n","        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","\n","    resized_img = cv2.resize(test_img, (1000, 700))\n","    cv2.imshow('Facial emotion analysis ', resized_img)\n","\n","    if cv2.waitKey(10) == ord('q'):  # wait until 'q' key is pressed\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOQVojxrcNYMFIJYB4nx7Ta","gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
